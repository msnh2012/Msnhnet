config:
  batch: 1
  channels: 3
  width: 224
  height: 224
#0
padding:
  top: 3
  down: 3
  left: 3
  right: 3
  paddingVal: 0
#1
conv:
  filters: 64
  kSizeX: 7
  kSizeY: 7
  paddingX: 0
  paddingY: 0
  strideX: 2
  strideY: 2
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#2
batchnorm:
  activation: none
#3
act:
  activation: relu
#4
padding:
  top: 1
  down: 1
  left: 1
  right: 1
  paddingVal: 0
#5
maxpool:
  kSizeX: 3
  kSizeY: 3
  paddingX: 0
  paddingY: 0
  strideX: 2
  strideY: 2
#6
conv:
  filters: 64
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#7
batchnorm:
  activation: none
#8
act:
  activation: relu
#9
conv:
  filters: 64
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#10
batchnorm:
  activation: none
#11
act:
  activation: relu
#12
conv:
  filters: 256
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#13
route:
  layers: 5
  addModel: 0
#14
conv:
  filters: 256
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#15
route:
  layers: 12
  addModel: 0
#16
batchnorm:
  activation: none
#17
route:
  layers: 14
  addModel: 0
#18
batchnorm:
  activation: none
#19
route:
  layers: 16,18
  addModel: 1
#20
act:
  activation: relu
#21
conv:
  filters: 64
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#22
batchnorm:
  activation: none
#23
act:
  activation: relu
#24
conv:
  filters: 64
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#25
batchnorm:
  activation: none
#26
act:
  activation: relu
#27
conv:
  filters: 256
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#28
batchnorm:
  activation: none
#29
route:
  layers: 28,20
  addModel: 1
#30
act:
  activation: relu
#31
conv:
  filters: 64
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#32
batchnorm:
  activation: none
#33
act:
  activation: relu
#34
conv:
  filters: 64
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#35
batchnorm:
  activation: none
#36
act:
  activation: relu
#37
conv:
  filters: 256
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#38
batchnorm:
  activation: none
#39
route:
  layers: 38,30
  addModel: 1
#40
act:
  activation: relu
#41
conv:
  filters: 128
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 2
  strideY: 2
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#42
batchnorm:
  activation: none
#43
act:
  activation: relu
#44
conv:
  filters: 128
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#45
batchnorm:
  activation: none
#46
act:
  activation: relu
#47
conv:
  filters: 512
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#48
route:
  layers: 40
  addModel: 0
#49
conv:
  filters: 512
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 2
  strideY: 2
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#50
route:
  layers: 47
  addModel: 0
#51
batchnorm:
  activation: none
#52
route:
  layers: 49
  addModel: 0
#53
batchnorm:
  activation: none
#54
route:
  layers: 51,53
  addModel: 1
#55
act:
  activation: relu
#56
conv:
  filters: 128
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#57
batchnorm:
  activation: none
#58
act:
  activation: relu
#59
conv:
  filters: 128
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#60
batchnorm:
  activation: none
#61
act:
  activation: relu
#62
conv:
  filters: 512
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#63
batchnorm:
  activation: none
#64
route:
  layers: 63,55
  addModel: 1
#65
act:
  activation: relu
#66
conv:
  filters: 128
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#67
batchnorm:
  activation: none
#68
act:
  activation: relu
#69
conv:
  filters: 128
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#70
batchnorm:
  activation: none
#71
act:
  activation: relu
#72
conv:
  filters: 512
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#73
batchnorm:
  activation: none
#74
route:
  layers: 73,65
  addModel: 1
#75
act:
  activation: relu
#76
conv:
  filters: 128
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#77
batchnorm:
  activation: none
#78
act:
  activation: relu
#79
conv:
  filters: 128
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#80
batchnorm:
  activation: none
#81
act:
  activation: relu
#82
conv:
  filters: 512
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#83
batchnorm:
  activation: none
#84
route:
  layers: 83,75
  addModel: 1
#85
act:
  activation: relu
#86
conv:
  filters: 256
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 2
  strideY: 2
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#87
batchnorm:
  activation: none
#88
act:
  activation: relu
#89
conv:
  filters: 256
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#90
batchnorm:
  activation: none
#91
act:
  activation: relu
#92
conv:
  filters: 1024
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#93
route:
  layers: 85
  addModel: 0
#94
conv:
  filters: 1024
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 2
  strideY: 2
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#95
route:
  layers: 92
  addModel: 0
#96
batchnorm:
  activation: none
#97
route:
  layers: 94
  addModel: 0
#98
batchnorm:
  activation: none
#99
route:
  layers: 96,98
  addModel: 1
#100
act:
  activation: relu
#101
conv:
  filters: 256
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#102
batchnorm:
  activation: none
#103
act:
  activation: relu
#104
conv:
  filters: 256
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#105
batchnorm:
  activation: none
#106
act:
  activation: relu
#107
conv:
  filters: 1024
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#108
batchnorm:
  activation: none
#109
route:
  layers: 108,100
  addModel: 1
#110
act:
  activation: relu
#111
conv:
  filters: 256
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#112
batchnorm:
  activation: none
#113
act:
  activation: relu
#114
conv:
  filters: 256
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#115
batchnorm:
  activation: none
#116
act:
  activation: relu
#117
conv:
  filters: 1024
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#118
batchnorm:
  activation: none
#119
route:
  layers: 118,110
  addModel: 1
#120
act:
  activation: relu
#121
conv:
  filters: 256
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#122
batchnorm:
  activation: none
#123
act:
  activation: relu
#124
conv:
  filters: 256
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#125
batchnorm:
  activation: none
#126
act:
  activation: relu
#127
conv:
  filters: 1024
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#128
batchnorm:
  activation: none
#129
route:
  layers: 128,120
  addModel: 1
#130
act:
  activation: relu
#131
conv:
  filters: 256
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#132
batchnorm:
  activation: none
#133
act:
  activation: relu
#134
conv:
  filters: 256
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#135
batchnorm:
  activation: none
#136
act:
  activation: relu
#137
conv:
  filters: 1024
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#138
batchnorm:
  activation: none
#139
route:
  layers: 138,130
  addModel: 1
#140
act:
  activation: relu
#141
conv:
  filters: 256
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#142
batchnorm:
  activation: none
#143
act:
  activation: relu
#144
conv:
  filters: 256
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#145
batchnorm:
  activation: none
#146
act:
  activation: relu
#147
conv:
  filters: 1024
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#148
batchnorm:
  activation: none
#149
route:
  layers: 148,140
  addModel: 1
#150
act:
  activation: relu
#151
conv:
  filters: 512
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 2
  strideY: 2
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#152
batchnorm:
  activation: none
#153
act:
  activation: relu
#154
conv:
  filters: 512
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#155
batchnorm:
  activation: none
#156
act:
  activation: relu
#157
conv:
  filters: 2048
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#158
route:
  layers: 150
  addModel: 0
#159
conv:
  filters: 2048
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 2
  strideY: 2
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#160
route:
  layers: 157
  addModel: 0
#161
batchnorm:
  activation: none
#162
route:
  layers: 159
  addModel: 0
#163
batchnorm:
  activation: none
#164
route:
  layers: 161,163
  addModel: 1
#165
act:
  activation: relu
#166
conv:
  filters: 512
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#167
batchnorm:
  activation: none
#168
act:
  activation: relu
#169
conv:
  filters: 512
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#170
batchnorm:
  activation: none
#171
act:
  activation: relu
#172
conv:
  filters: 2048
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#173
batchnorm:
  activation: none
#174
route:
  layers: 173,165
  addModel: 1
#175
act:
  activation: relu
#176
conv:
  filters: 512
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#177
batchnorm:
  activation: none
#178
act:
  activation: relu
#179
conv:
  filters: 512
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#180
batchnorm:
  activation: none
#181
act:
  activation: relu
#182
conv:
  filters: 2048
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
#183
batchnorm:
  activation: none
#184
route:
  layers: 183,175
  addModel: 1
#185
act:
  activation: relu
#186
globalavgpool:
  #187
connect:
  output: 1000
#188
softmax:
  groups: 1
